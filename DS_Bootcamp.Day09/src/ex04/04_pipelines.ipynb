{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 04\n",
    "# Pipelines and OOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "  train_test_split,\n",
    "  GridSearchCV,\n",
    "  ParameterGrid,\n",
    ")\n",
    "\n",
    "from sklearn.base import (\n",
    "  BaseEstimator,\n",
    "  TransformerMixin,\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "  OneHotEncoder\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import (\n",
    "  Pipeline,\n",
    ")\n",
    "\n",
    "from sklearn.tree import (\n",
    "  DecisionTreeClassifier,\n",
    ")\n",
    "\n",
    "from sklearn.svm import (\n",
    "  SVC\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "  accuracy_score,\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "  RandomForestClassifier,\n",
    ")\n",
    "\n",
    "from typing import (\n",
    "  List,\n",
    ")\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import joblib\n",
    "\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create three custom transformers, the first two out of which will be used within a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
    "\n",
    "1. `FeatureExtractor()` class:\n",
    " - Takes a dataframe with `uid`, `labname`, `numTrials`, `timestamp` from the file [`checker_submits.csv`](https://drive.google.com/file/d/14voc4fNJZiLEFaZyd8nEG-lQt5JjatYw/view?usp=sharing).\n",
    " - Extracts `hour` from `timestamp`.\n",
    " - Extracts `weekday` from `timestamp` (numbers).\n",
    " - Drops the `timestamp` column.\n",
    " - Returns the new dataframe.\n",
    "\n",
    "\n",
    "2. `MyOneHotEncoder()` class:\n",
    " - Takes the dataframe from the result of the previous transformation and the name of the target column.\n",
    " - Identifies all the categorical features and transforms them with `OneHotEncoder()`. If the target column is categorical too, then the transformation should not apply to it.\n",
    " - Drops the initial categorical features.\n",
    " - Returns the dataframe with the features and the series with the target column.\n",
    "\n",
    "\n",
    "3. `TrainValidationTest()` class:\n",
    " - Takes `X` and `y`.\n",
    " - Returns `X_train`, `X_valid`, `X_test`, `y_train`, `y_valid`, `y_test` (`test_size=0.2`, `random_state=21`, `stratified`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(TransformerMixin, BaseEstimator):\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def fit(self, X=None, y=None):\n",
    "    return self\n",
    "    \n",
    "  def transform(self, X=None, y=None):\n",
    "    df = X.copy()\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['dayofweek'] = df['timestamp'].dt.weekday\n",
    "    return df.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOneHotEncoder(OneHotEncoder):\n",
    "  def __init__(self,target_column: str):\n",
    "    super().__init__(sparse=False)\n",
    "    self.target_column = target_column\n",
    "\n",
    "  def _select_categories(self, X : pd.DataFrame):\n",
    "    categories = X.select_dtypes(include=['category', 'object'])\n",
    "    if self.target_column in categories.columns:\n",
    "      categories = categories.drop(self.target_column, axis=1)\n",
    "    return categories\n",
    "  \n",
    "  def fit(self, X, y=None):\n",
    "    subset = self._select_categories(X.copy())\n",
    "    return super().fit(subset)\n",
    "\n",
    "  def transform(self, X):\n",
    "    df = X.copy()\n",
    "    target = df[self.target_column]\n",
    "    df.drop(self.target_column, axis=1, inplace=True)\n",
    "\n",
    "    subset = self._select_categories(df)\n",
    "    encoded_df = pd.DataFrame(super().transform(subset), columns=self.get_feature_names(input_features=subset.columns))\n",
    "\n",
    "    return pd.concat([df.drop(subset.columns, axis=1), encoded_df], axis=1), target\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraninValidationTest():\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "\n",
    "  def __iter__(self):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "      self.X,\n",
    "      self.y, \n",
    "      test_size=0.2,\n",
    "      random_state=21, \n",
    "      stratify=self.y\n",
    "    )\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "      X_train,\n",
    "      y_train, \n",
    "      test_size=0.2,\n",
    "      random_state=21, \n",
    "      stratify=y_train\n",
    "    )\n",
    "\n",
    "    return iter((X_train, X_valid, X_test, y_train, y_valid, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model selection pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelSelection()` class\n",
    "\n",
    " - Takes a list of `GridSearchCV` instances and a dict where the keys are the indexes from that list and the values are the names of the models, the example is below in the reverse order (from high-level to low-level perspective):\n",
    "\n",
    "```\n",
    "ModelSelection(grids, grid_dict)\n",
    "\n",
    "grids = [gs_svm, gs_tree, gs_rf]\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=svm, param_grid=svm_params, scoring='accuracy', cv=2, n_jobs=jobs), where jobs you can specify by yourself\n",
    "\n",
    "svm_params = [{'kernel':('linear', 'rbf', 'sigmoid'), 'C':[0.01, 0.1, 1, 1.5, 5, 10], 'gamma': ['scale', 'auto'], 'class_weight':('balanced', None), 'random_state':[21], 'probability':[True]}]\n",
    "```\n",
    "\n",
    " - Method `choose()` takes `X_train`, `y_train`, `X_valid`, `y_valid` and returns the name of the best classifier among all the models on the validation set\n",
    " - Method `best_results()` returns a dataframe with the columns `model`, `params`, `valid_score` where the rows are the best models within each class of models.\n",
    "\n",
    "```\n",
    "model\tparams\tvalid_score\n",
    "0\tSVM\t{'C': 10, 'class_weight': None, 'gamma': 'auto...\t0.772727\n",
    "1\tDecision Tree\t{'class_weight': 'balanced', 'criterion': 'gin...\t0.801484\n",
    "2\tRandom Forest\t{'class_weight': None, 'criterion': 'entropy',...\t0.855288\n",
    "```\n",
    "\n",
    " - When you iterate through the parameters of a model class, print the name of that class and show the progress using `tqdm.notebook`, in the end of the cycle print the best model of that class.\n",
    "\n",
    "```\n",
    "Estimator: SVM\n",
    "100%\n",
    "125/125 [01:32<00:00, 1.36it/s]\n",
    "Best params: {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True, 'random_state': 21}\n",
    "Best training accuracy: 0.773\n",
    "Validation set accuracy score for best params: 0.878 \n",
    "\n",
    "Estimator: Decision Tree\n",
    "100%\n",
    "57/57 [01:07<00:00, 1.22it/s]\n",
    "Best params: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 21, 'random_state': 21}\n",
    "Best training accuracy: 0.801\n",
    "Validation set accuracy score for best params: 0.867 \n",
    "\n",
    "Estimator: Random Forest\n",
    "100%\n",
    "284/284 [06:47<00:00, 1.13s/it]\n",
    "Best params: {'class_weight': None, 'criterion': 'entropy', 'max_depth': 22, 'n_estimators': 50, 'random_state': 21}\n",
    "Best training accuracy: 0.855\n",
    "Validation set accuracy score for best params: 0.907 \n",
    "\n",
    "Classifier with best validation set accuracy: Random Forest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSelection():\n",
    "  def __init__(self, grids : List[GridSearchCV], grid_dict):\n",
    "    self.grids = grids\n",
    "    self.grid_dict = grid_dict\n",
    "    self.results = []\n",
    "\n",
    "  @contextmanager\n",
    "  def _tqdm_joblib(self,tqdm_object):\n",
    "      class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "          def __init__(self, *args, **kwargs):\n",
    "              super().__init__(*args, **kwargs)\n",
    "\n",
    "          def __call__(self, *args, **kwargs):\n",
    "              tqdm_object.update(n=self.batch_size)\n",
    "              return super().__call__(*args, **kwargs)\n",
    "\n",
    "      old_callback = joblib.parallel.BatchCompletionCallBack\n",
    "      joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "      try:\n",
    "          yield\n",
    "      finally:\n",
    "          joblib.parallel.BatchCompletionCallBack = old_callback\n",
    "\n",
    "  def _custom_search(self, X_train, X_valid, y_train, y_valid):\n",
    "    for grid in self.grids:\n",
    "      grid_idx = self.grids.index(grid)\n",
    "      params = self.grid_dict[grid_idx]\n",
    "\n",
    "      total_tasks = len(ParameterGrid(params)) * (grid.cv if grid.cv else 5)\n",
    "      estimator_name = grid.get_params(deep=False)['estimator'].__class__.__name__\n",
    "      with tqdm(total=total_tasks, desc=f'Estimator: {estimator_name}', leave=True) as pbar:\n",
    "          with self._tqdm_joblib(pbar):\n",
    "              grid.fit(X_train, y_train)\n",
    "\n",
    "      best_score = grid.best_score_\n",
    "      best_params = grid.best_params_\n",
    "      self.results.append((grid_idx, best_params, best_score))\n",
    "\n",
    "      print(f\"Best params: {best_params}\\n\"\n",
    "            f\"Best training accuracy: {best_score:.3f}\\n\"\n",
    "            f\"Validation set accuracy score for best params: {accuracy_score(y_valid, grid.predict(X_valid)):.3f}\\n\") \n",
    "\n",
    "  def choose(self, X_train, X_valid, y_train, y_valid):\n",
    "    if not self.results:\n",
    "      self._custom_search(X_train, X_valid, y_train, y_valid)\n",
    "\n",
    "    results = [res[2] for res in self.results]\n",
    "    best_estimator = self.grids[np.argmax(results)].get_params(deep=False)['estimator'].__class__.__name__\n",
    "\n",
    "    print(f'Classifier with best validation set accuracy: {best_estimator}')\n",
    "\n",
    "    return best_estimator\n",
    "\n",
    "  def best_results(self):\n",
    "    models = [\n",
    "      self.grids[grid[0]].get_params(deep=False)['estimator'].__class__.__name__\n",
    "      for grid \n",
    "      in self.results\n",
    "    ]\n",
    "\n",
    "    result = pd.DataFrame(self.results, columns=['model','params', 'valid_score'])\n",
    "    result['model'] = models\n",
    "    result.sort_values('valid_score', ascending=False, inplace=True)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Finalize()` class\n",
    " - Takes an estimator.\n",
    " - Method `final_score()` takes `X_train`, `y_train`, `X_test`, `y_test` and returns the accuracy of the model as in the example below:\n",
    "```\n",
    "final.final_score(X_train, y_train, X_test, y_test)\n",
    "Accuracy of the final model is 0.908284023668639\n",
    "```\n",
    " - Method `save_model()` takes a path, saves the model to this path and prints that the model was successfully saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Finalize():\n",
    "  def __init__(self, estimator):\n",
    "    self.estimator = estimator\n",
    "  \n",
    "  def final_score(self, X_train, y_train, X_test, y_test):\n",
    "    self.estimator.fit(X_train, y_train)\n",
    "    score = accuracy_score(y_test, self.estimator.predict(X_test))\n",
    "\n",
    "    print(f'Accuracy of the final moddel is {score}')\n",
    "    return score\n",
    "  \n",
    "  def save_model(self, path):\n",
    "    res = joblib.dump(self.estimator, path)\n",
    "\n",
    "    print(f'model {\"saved successfully\" if len(res) == 1 else \"NOT SAVED\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data from the file (****name of file****).\n",
    "2. Create the preprocessing pipeline that consists of two custom transformers: `FeatureExtractor()` and `MyOneHotEncoder()`:\n",
    "```\n",
    "preprocessing = Pipeline([('feature_extractor', FeatureExtractor()), ('onehot_encoder', MyOneHotEncoder('dayofweek'))])\n",
    "```\n",
    "3. Use that pipeline and its method `fit_transform()` on the initial dataset.\n",
    "```\n",
    "data = preprocessing.fit_transform(df)\n",
    "```\n",
    "4. Get `X_train`, `X_valid`, `X_test`, `y_train`, `y_valid`, `y_test` using `TrainValidationTest()` and the result of the pipeline.\n",
    "5. Create an instance of `ModelSelection()`, use the method `choose()` applying it to the models that you want and parameters that you want, get the dataframe of the best results.\n",
    "6. create an instance of `Finalize()` with your best model, use method `final_score()` and save the model in the format: `name_of_the_model_{accuracy on test dataset}.sav`.\n",
    "\n",
    "That is it, congrats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "uid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "labname",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "numTrials",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "ref": "176d2ebd-7db9-4082-ac35-23ef90d8cab9",
       "rows": [
        [
         "0",
         "user_4",
         "project1",
         "1",
         "2020-04-17 05:19:02.744528"
        ],
        [
         "1",
         "user_4",
         "project1",
         "2",
         "2020-04-17 05:22:45.549397"
        ],
        [
         "2",
         "user_4",
         "project1",
         "3",
         "2020-04-17 05:34:24.422370"
        ],
        [
         "3",
         "user_4",
         "project1",
         "4",
         "2020-04-17 05:43:27.773992"
        ],
        [
         "4",
         "user_4",
         "project1",
         "5",
         "2020-04-17 05:46:32.275104"
        ],
        [
         "5",
         "user_4",
         "project1",
         "6",
         "2020-04-17 05:50:27.860908"
        ],
        [
         "6",
         "user_4",
         "project1",
         "7",
         "2020-04-17 05:52:56.335091"
        ],
        [
         "7",
         "user_4",
         "laba04",
         "1",
         "2020-04-17 11:33:17.366400"
        ],
        [
         "8",
         "user_4",
         "laba04",
         "2",
         "2020-04-17 11:40:05.237273"
        ],
        [
         "9",
         "user_4",
         "laba04",
         "3",
         "2020-04-17 11:44:20.707058"
        ],
        [
         "10",
         "user_4",
         "laba04s",
         "1",
         "2020-04-17 11:48:41.992466"
        ],
        [
         "11",
         "user_4",
         "laba04s",
         "2",
         "2020-04-17 11:50:11.456634"
        ],
        [
         "12",
         "user_4",
         "laba04s",
         "3",
         "2020-04-17 12:46:12.054682"
        ],
        [
         "13",
         "user_17",
         "project1",
         "1",
         "2020-04-18 07:56:45.408648"
        ],
        [
         "14",
         "user_30",
         "laba04",
         "1",
         "2020-04-18 13:36:53.971502"
        ],
        [
         "15",
         "user_2",
         "laba04",
         "1",
         "2020-04-18 13:42:35.482008"
        ],
        [
         "16",
         "user_2",
         "laba04s",
         "1",
         "2020-04-18 13:51:22.291271"
        ],
        [
         "17",
         "user_2",
         "laba04s",
         "2",
         "2020-04-18 13:53:17.423114"
        ],
        [
         "18",
         "user_2",
         "laba04s",
         "3",
         "2020-04-18 14:30:59.279089"
        ],
        [
         "19",
         "user_30",
         "laba04s",
         "1",
         "2020-04-18 14:51:37.498399"
        ],
        [
         "20",
         "user_2",
         "laba04s",
         "4",
         "2020-04-18 15:13:27.655666"
        ],
        [
         "21",
         "user_14",
         "laba04",
         "1",
         "2020-04-18 15:14:00.312338"
        ],
        [
         "22",
         "user_14",
         "laba04",
         "2",
         "2020-04-18 15:20:33.198766"
        ],
        [
         "23",
         "user_14",
         "laba04",
         "3",
         "2020-04-18 15:24:12.047491"
        ],
        [
         "24",
         "user_14",
         "laba04",
         "4",
         "2020-04-18 15:24:53.299514"
        ],
        [
         "25",
         "user_14",
         "laba04",
         "5",
         "2020-04-18 15:30:17.096916"
        ],
        [
         "26",
         "user_14",
         "laba04",
         "6",
         "2020-04-18 15:33:14.440380"
        ],
        [
         "27",
         "user_2",
         "laba04s",
         "5",
         "2020-04-18 15:33:20.565406"
        ],
        [
         "28",
         "user_14",
         "laba04",
         "7",
         "2020-04-18 15:34:22.274256"
        ],
        [
         "29",
         "user_14",
         "laba04",
         "8",
         "2020-04-18 15:35:48.841969"
        ],
        [
         "30",
         "user_14",
         "laba04",
         "9",
         "2020-04-18 15:45:13.236352"
        ],
        [
         "31",
         "user_14",
         "laba04",
         "10",
         "2020-04-18 15:46:15.473674"
        ],
        [
         "32",
         "user_14",
         "laba04",
         "11",
         "2020-04-18 15:49:49.293560"
        ],
        [
         "33",
         "user_12",
         "laba04",
         "1",
         "2020-04-18 17:07:51.767358"
        ],
        [
         "34",
         "user_12",
         "laba04",
         "2",
         "2020-04-18 17:32:52.474915"
        ],
        [
         "35",
         "user_12",
         "laba04",
         "3",
         "2020-04-18 17:34:09.414675"
        ],
        [
         "36",
         "user_12",
         "laba04",
         "4",
         "2020-04-18 17:38:05.714027"
        ],
        [
         "37",
         "user_14",
         "laba04",
         "12",
         "2020-04-18 18:10:35.687654"
        ],
        [
         "38",
         "user_2",
         "laba04s",
         "6",
         "2020-04-18 18:12:36.913229"
        ],
        [
         "39",
         "user_14",
         "laba04",
         "13",
         "2020-04-18 18:47:11.295818"
        ],
        [
         "40",
         "user_14",
         "laba04",
         "14",
         "2020-04-18 18:58:31.263729"
        ],
        [
         "41",
         "user_14",
         "laba04",
         "15",
         "2020-04-18 19:25:59.869852"
        ],
        [
         "42",
         "user_14",
         "laba04",
         "16",
         "2020-04-18 19:38:12.034655"
        ],
        [
         "43",
         "user_2",
         "laba04s",
         "7",
         "2020-04-18 19:51:12.195982"
        ],
        [
         "44",
         "user_14",
         "laba04",
         "17",
         "2020-04-18 20:01:14.446476"
        ],
        [
         "45",
         "user_14",
         "laba04",
         "18",
         "2020-04-18 20:01:24.594980"
        ],
        [
         "46",
         "user_2",
         "laba04s",
         "8",
         "2020-04-18 21:30:51.210546"
        ],
        [
         "47",
         "user_14",
         "laba04",
         "19",
         "2020-04-18 21:42:46.277260"
        ],
        [
         "48",
         "user_8",
         "laba04",
         "1",
         "2020-04-18 21:53:36.058389"
        ],
        [
         "49",
         "user_14",
         "laba04s",
         "1",
         "2020-04-18 22:30:30.247628"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 1686
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>labname</th>\n",
       "      <th>numTrials</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-04-17 05:19:02.744528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-17 05:22:45.549397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-04-17 05:34:24.422370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-17 05:43:27.773992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_4</td>\n",
       "      <td>project1</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-04-17 05:46:32.275104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>user_19</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-05-21 20:01:48.959966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-05-21 20:18:54.487900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-05-21 20:19:06.872761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>8</td>\n",
       "      <td>2020-05-21 20:22:41.877806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>user_1</td>\n",
       "      <td>laba06s</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-05-21 20:37:00.290491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          uid   labname  numTrials                  timestamp\n",
       "0      user_4  project1          1 2020-04-17 05:19:02.744528\n",
       "1      user_4  project1          2 2020-04-17 05:22:45.549397\n",
       "2      user_4  project1          3 2020-04-17 05:34:24.422370\n",
       "3      user_4  project1          4 2020-04-17 05:43:27.773992\n",
       "4      user_4  project1          5 2020-04-17 05:46:32.275104\n",
       "...       ...       ...        ...                        ...\n",
       "1681  user_19   laba06s          9 2020-05-21 20:01:48.959966\n",
       "1682   user_1   laba06s          6 2020-05-21 20:18:54.487900\n",
       "1683   user_1   laba06s          7 2020-05-21 20:19:06.872761\n",
       "1684   user_1   laba06s          8 2020-05-21 20:22:41.877806\n",
       "1685   user_1   laba06s          9 2020-05-21 20:37:00.290491\n",
       "\n",
       "[1686 rows x 4 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../datasets/checker_submits.csv', parse_dates=['timestamp'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([('feature_extractor', FeatureExtractor()), ('onehot_encoder', MyOneHotEncoder('dayofweek'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessing.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = TraninValidationTest(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = dict(\n",
    "    kernel=['linear', 'rbf', 'sigmoid'],\n",
    "    C=[0.01, 0.1, 1, 1.5, 5, 10],\n",
    "    gamma=['scale', 'auto'],\n",
    "    class_weight=['balanced', None],\n",
    "    random_state=[21],\n",
    "    probability=[True]\n",
    ")\n",
    "\n",
    "tree_params = dict(\n",
    "    max_depth=range(1, 49),\n",
    "    class_weight=['balanced', None],\n",
    "    criterion=['gini', 'entropy'],\n",
    "    random_state=[21]\n",
    ")\n",
    "forest_params =  dict(\n",
    "    n_estimators=[5, 10, 50, 100],\n",
    "    max_depth=range(1, 49),\n",
    "    class_weight=['balanced', None],\n",
    "    criterion=['entropy','gini'],\n",
    "    random_state=[21]\n",
    ")\n",
    "\n",
    "gs_svm = GridSearchCV(\n",
    "  SVC(),\n",
    "  svm_params,\n",
    "  scoring='accuracy',\n",
    "  n_jobs=-1,\n",
    "  verbose=0,\n",
    ")\n",
    "gs_tree = GridSearchCV(\n",
    "  DecisionTreeClassifier(),\n",
    "  tree_params,\n",
    "  scoring='accuracy',\n",
    "  n_jobs=-1,\n",
    "  verbose=0,\n",
    "  \n",
    ")\n",
    "gs_forest = GridSearchCV(\n",
    "  RandomForestClassifier(),\n",
    "  forest_params,\n",
    "  scoring='accuracy',\n",
    "  n_jobs=-1,\n",
    "  verbose=0,\n",
    ")\n",
    "\n",
    "grids = [\n",
    "  gs_svm,\n",
    "  gs_tree,\n",
    "  gs_forest\n",
    "]\n",
    "\n",
    "grid_dict = {\n",
    "  grids.index(gs_svm): svm_params,\n",
    "  grids.index(gs_tree): tree_params,\n",
    "  grids.index(gs_forest): forest_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = ModelSelection(grids, grid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31850330ef8a447680e63d48be4cbd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Estimator: SVC:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True, 'random_state': 21}\n",
      "Best training accuracy: 0.842\n",
      "Validation set accuracy score for best params: 0.878\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456a4372c1284748a38d57b882792022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Estimator: DecisionTreeClassifier:   0%|          | 0/960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'class_weight': None, 'criterion': 'gini', 'max_depth': 26, 'random_state': 21}\n",
      "Best training accuracy: 0.853\n",
      "Validation set accuracy score for best params: 0.867\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7446bdacdf3144a293b28785a026ee00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Estimator: RandomForestClassifier:   0%|          | 0/3840 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 35, 'n_estimators': 50, 'random_state': 21}\n",
      "Best training accuracy: 0.898\n",
      "Validation set accuracy score for best params: 0.904\n",
      "\n",
      "Classifier with best validation set accuracy: RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "best_model_name = selector.choose(X_train,X_valid, y_train, y_valid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "valid_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a090feca-9d79-42ee-8dad-26386a476b44",
       "rows": [
        [
         "2",
         "RandomForestClassifier",
         "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 35, 'n_estimators': 50, 'random_state': 21}",
         "0.8979155900086132"
        ],
        [
         "1",
         "DecisionTreeClassifier",
         "{'class_weight': None, 'criterion': 'gini', 'max_depth': 26, 'random_state': 21}",
         "0.8533893195521103"
        ],
        [
         "0",
         "SVC",
         "{'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True, 'random_state': 21}",
         "0.8422609819121447"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>valid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.897916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.853389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'gamma': 'auto...</td>\n",
       "      <td>0.842261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                                             params  \\\n",
       "2  RandomForestClassifier  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "1  DecisionTreeClassifier  {'class_weight': None, 'criterion': 'gini', 'm...   \n",
       "0                     SVC  {'C': 10, 'class_weight': None, 'gamma': 'auto...   \n",
       "\n",
       "   valid_score  \n",
       "2     0.897916  \n",
       "1     0.853389  \n",
       "0     0.842261  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results = selector.best_results()\n",
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "  'SVC': SVC,\n",
    "  'DecisionTreeClassifier': DecisionTreeClassifier,\n",
    "  'RandomForestClassifier': RandomForestClassifier,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       max_depth=35, n_estimators=50, random_state=21)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models_dict[best_model_name](**best_results.set_index('model').loc[best_model_name,'params'])\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = Finalize(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the final moddel is 0.9171597633136095\n"
     ]
    }
   ],
   "source": [
    "accuracy = final.final_score(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved successfully\n"
     ]
    }
   ],
   "source": [
    "final.save_model(f'name_of_the_model_{accuracy}.sav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".legacy_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
